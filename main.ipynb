{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Daniel-T-Henriques/CIFAR10-image-classifier/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw_Uvc7bBEIB"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Dd_C-pufBEID",
        "outputId": "ed348ba4-b2e2-443d-8d48-1aba6ec0556c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'transforms' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ac45f9671a06>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m train_dataset = torchvision.datasets.CIFAR10(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.utils\n",
        "import torch.utils.data\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transf\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, accuracy_score, f1_score, precision_score\n",
        ")\n",
        "\n",
        "transform = transf.Compose([transforms.ToTensor(), transforms.Normalize((0.5),(0,5))])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root-\"./data\", transform=transform, train=True, download=True\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", transform=transform, train=False, download=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=train_dataset, batch_size=32, shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset=test_dataset, batch_size=32, shuffle=False\n",
        ")\n",
        "\n",
        "examples = iter(train_loader)\n",
        "images, labels = next(examples)\n",
        "\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.imshow(images[i].permute(2, 1, 0))\n",
        "    plt.title(f\"Label: {labels[i].item()}\")\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uy3iwGiPKoO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Jn8K_E3BEIE"
      },
      "source": [
        "### Criando a rede neural"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDVK6bI_BEIF"
      },
      "outputs": [],
      "source": [
        "class NeuralNet(nn.Module): #NN Herda nn_Module\n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.flatten = nn.Flatten() #Achatando imagem\n",
        "\n",
        "        # Neurônio 1: 32*32*3 pixels de entrada (canal RGB), 128 saídas\n",
        "        self.fc1 = nn.Linear(32*32*3, 512)\n",
        "\n",
        "        # Neurônio 2: 510 entradas, 128 px de saída\n",
        "        self.fc2 = nn.Linear(510, 128)\n",
        "\n",
        "        # Neurônio 3: 128 px de entrada, classif. em 10 tipos (0-9)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kM3Qujx6BEIG"
      },
      "outputs": [],
      "source": [
        "model = NeuralNet()\n",
        "model = model.to(\"cuda\")\n",
        "\n",
        "# Função de perda e otimizador\n",
        "criterium = nn.CrossEntropyLoss() #Entropia cruzada\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Treinamento\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for images, labels in train_loader:\n",
        "        # Zerar os gradientes\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Passar pelo modelo\n",
        "        outputs = model(images.to(\"cuda\"))\n",
        "\n",
        "        # Calcular a perda\n",
        "        loss = criterium(outputs, labels.to(\"cuda\"))\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # Atualizar os pesos\n",
        "        optimizer.step()\n",
        "\n",
        "    print((f\"Epoch: {epoch+1}/{num_epochs}\\nLoss: {loss.item():.5f}\\n\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.device(\"cuda:0\"))"
      ],
      "metadata": {
        "id": "13M7GGyWMb6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images.to(\"cuda\"))\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.numpy())\n",
        "\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds, average=\"weighted\")\n",
        "recall = recall_score(all_labels, all_preds, average=\"weighted\")\n",
        "f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.8f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "ysDtBL90NWvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Reds\", xticklabels=np.arange(10), yticklabels=np.arange(10))\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NJwsnYogOjsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = iter(test_loader)"
      ],
      "metadata": {
        "id": "fjm-jwy8PBc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(examples)\n",
        "ouputs = model(images.to(\"cuda\"))\n",
        "_, preds = torch.max(outputs, 1)\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.imshow(images[i].permute(2, 1, 0))"
      ],
      "metadata": {
        "id": "XeIVpRUdPFlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QjQMnSkvPlfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC-vQ7ThBEIF"
      },
      "source": [
        "### Baixando o dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k99LkZ0oBEIG"
      },
      "outputs": [],
      "source": [
        "transform = transf.Compose([transf.ToTensor(), transf.Normalize((0.5), (0.5)) ])\n",
        "\n",
        "# Criando dataset de treino e de teste\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", transform = transform, train=True, download=True\n",
        ")\n",
        "\n",
        "test_dataset = rain_dataset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", transform = transform, train=False, download=True\n",
        ")\n",
        "\n",
        "# Criando o batch (que adicionará batch_size imagens ao dataset quando ele acabar)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset = train_dataset, batch_size = 32, shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNeMMnGpBEIG"
      },
      "outputs": [],
      "source": [
        "examples = iter(train_loader)\n",
        "images, labels = next(examples)\n",
        "\n",
        "for i in range(9):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(images[i][0])\n",
        "    plt.title(f\"label:{labels[i].item()}\")\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}